import pandas as pd
import os
import glob

def check_dataset_split(csv_file_path, v16_base_path):
    """
    æ£€æŸ¥v1.6æ•°æ®é›†çš„åˆ’åˆ†æ˜¯å¦ç¬¦åˆlabels_consensus.csvçš„è¦æ±‚
    
    Args:
        csv_file_path: labels_consensus.csvæ–‡ä»¶è·¯å¾„
        v16_base_path: v1.6æ•°æ®é›†çš„åŸºç¡€è·¯å¾„ï¼ŒåŒ…å«testã€trainã€validationæ–‡ä»¶å¤¹
    """
    
    # è¯»å–æ ‡ç­¾æ–‡ä»¶
    print("è¯»å–labels_consensus.csvæ–‡ä»¶...")
    try:
        labels_df = pd.read_csv(csv_file_path)
        print(f"æˆåŠŸè¯»å–{len(labels_df)}æ¡è®°å½•")
    except Exception as e:
        print(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['FileName', 'EmoClass', 'EmoAct', 'EmoVal', 'EmoDom', 'SpkrID', 'Gender', 'Split_Set']
    missing_columns = [col for col in required_columns if col not in labels_df.columns]
    if missing_columns:
        print(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
        return
    
    # æŒ‰Split_Setåˆ†ç»„
    split_groups = labels_df.groupby('Split_Set')
    print(f"\næ ‡ç­¾æ–‡ä»¶ä¸­çš„æ•°æ®é›†åˆ’åˆ†:")
    for split_name, group in split_groups:
        print(f"  {split_name}: {len(group)}ä¸ªæ–‡ä»¶")
    
    # æ£€æŸ¥v1.6ç›®å½•ç»“æ„
    splits_to_check = ['test', 'train', 'validation']
    results = {}
    
    for split_name in splits_to_check:
        split_path = os.path.join(v16_base_path, split_name)
        
        if not os.path.exists(split_path):
            print(f"\nè­¦å‘Š: ç›®å½•ä¸å­˜åœ¨ - {split_path}")
            continue
            
        print(f"\næ£€æŸ¥ {split_name} æ•°æ®é›†...")
        
        # è·å–è¯¥splitåœ¨CSVä¸­åº”è¯¥åŒ…å«çš„æ–‡ä»¶
        expected_files = set()
        if split_name in labels_df['Split_Set'].values:
            expected_files = set(labels_df[labels_df['Split_Set'] == split_name]['FileName'].values)
        
        # è·å–å®é™…å­˜åœ¨çš„æ–‡ä»¶ï¼ˆæ”¯æŒå¸¸è§çš„éŸ³é¢‘æ ¼å¼ï¼‰
        audio_extensions = ['*.wav', '*.mp3', '*.flac', '*.m4a', '*.aac']
        actual_files = set()
        
        for ext in audio_extensions:
            files = glob.glob(os.path.join(split_path, ext))
            actual_files.update([os.path.basename(f) for f in files])
        
        # ä¹Ÿæ£€æŸ¥å­ç›®å½•
        for root, dirs, files in os.walk(split_path):
            for file in files:
                if any(file.lower().endswith(ext[1:]) for ext in audio_extensions):
                    actual_files.add(file)
        
        # æ¯”è¾ƒç»“æœ
        missing_files = expected_files - actual_files
        extra_files = actual_files - expected_files
        correct_files = expected_files & actual_files
        
        results[split_name] = {
            'expected_count': len(expected_files),
            'actual_count': len(actual_files),
            'correct_count': len(correct_files),
            'missing_count': len(missing_files),
            'extra_count': len(extra_files),
            'missing_files': missing_files,
            'extra_files': extra_files
        }
        
        print(f"  é¢„æœŸæ–‡ä»¶æ•°: {len(expected_files)}")
        print(f"  å®é™…æ–‡ä»¶æ•°: {len(actual_files)}")
        print(f"  æ­£ç¡®åŒ¹é…æ•°: {len(correct_files)}")
        print(f"  ç¼ºå¤±æ–‡ä»¶æ•°: {len(missing_files)}")
        print(f"  å¤šä½™æ–‡ä»¶æ•°: {len(extra_files)}")
        
        if missing_files:
            print(f"  ç¼ºå¤±çš„æ–‡ä»¶ (å‰10ä¸ª): {list(missing_files)[:10]}")
            if len(missing_files) > 10:
                print(f"    ... è¿˜æœ‰ {len(missing_files) - 10} ä¸ªæ–‡ä»¶")
        
        if extra_files:
            print(f"  å¤šä½™çš„æ–‡ä»¶ (å‰10ä¸ª): {list(extra_files)[:10]}")
            if len(extra_files) > 10:
                print(f"    ... è¿˜æœ‰ {len(extra_files) - 10} ä¸ªæ–‡ä»¶")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print(f"\n{'='*50}")
    print("æ€»ç»“æŠ¥å‘Š:")
    print(f"{'='*50}")
    
    total_errors = 0
    for split_name, result in results.items():
        accuracy = (result['correct_count'] / result['expected_count'] * 100) if result['expected_count'] > 0 else 0
        print(f"\n{split_name.upper()} æ•°æ®é›†:")
        print(f"  å‡†ç¡®ç‡: {accuracy:.2f}%")
        print(f"  åŒ¹é…åº¦: {result['correct_count']}/{result['expected_count']}")
        
        if result['missing_count'] > 0 or result['extra_count'] > 0:
            print(f"  âŒ å‘ç°é—®é¢˜: ç¼ºå¤±{result['missing_count']}ä¸ªæ–‡ä»¶ï¼Œå¤šä½™{result['extra_count']}ä¸ªæ–‡ä»¶")
            total_errors += result['missing_count'] + result['extra_count']
        else:
            print(f"  âœ… å®Œå…¨åŒ¹é…")
    
    if total_errors == 0:
        print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®é›†åˆ’åˆ†éƒ½ç¬¦åˆlabels_consensus.csvçš„è¦æ±‚ï¼")
    else:
        print(f"\nâš ï¸  å‘ç° {total_errors} ä¸ªä¸åŒ¹é…çš„é—®é¢˜éœ€è¦å¤„ç†")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_path = "dataset_split_check_report.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("æ•°æ®é›†åˆ’åˆ†æ£€æŸ¥æŠ¥å‘Š\n")
        f.write("="*50 + "\n\n")
        
        for split_name, result in results.items():
            f.write(f"{split_name.upper()} æ•°æ®é›†:\n")
            f.write(f"é¢„æœŸæ–‡ä»¶æ•°: {result['expected_count']}\n")
            f.write(f"å®é™…æ–‡ä»¶æ•°: {result['actual_count']}\n")
            f.write(f"æ­£ç¡®åŒ¹é…æ•°: {result['correct_count']}\n")
            f.write(f"ç¼ºå¤±æ–‡ä»¶æ•°: {result['missing_count']}\n")
            f.write(f"å¤šä½™æ–‡ä»¶æ•°: {result['extra_count']}\n\n")
            
            if result['missing_files']:
                f.write("ç¼ºå¤±çš„æ–‡ä»¶:\n")
                for file in sorted(result['missing_files']):
                    f.write(f"  - {file}\n")
                f.write("\n")
            
            if result['extra_files']:
                f.write("å¤šä½™çš„æ–‡ä»¶:\n")
                for file in sorted(result['extra_files']):
                    f.write(f"  - {file}\n")
                f.write("\n")
            
            f.write("-" * 30 + "\n\n")
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    # é…ç½®æ–‡ä»¶è·¯å¾„
    csv_file_path = "/mnt/shareEEx/liuyang/code/SE_IMR_MTL_KD/data/labels/v1.6/label/labels_concensus.csv"  # ä¿®æ”¹ä¸ºä½ çš„CSVæ–‡ä»¶è·¯å¾„
    v16_base_path = "/mnt/shareEEx/liuyang/code/SE_IMR_MTL_KD/data/organized_datasets/v1.6"  # ä¿®æ”¹ä¸ºä½ çš„v1.6æ•°æ®é›†è·¯å¾„
    
    print("æ•°æ®é›†åˆ’åˆ†éªŒè¯è„šæœ¬")
    print("="*50)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(csv_file_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {csv_file_path}")
        return
    
    if not os.path.exists(v16_base_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {v16_base_path}")
        return
    
    # æ‰§è¡Œæ£€æŸ¥
    check_dataset_split(csv_file_path, v16_base_path)

if __name__ == "__main__":
    main()